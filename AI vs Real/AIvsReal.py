# -*- coding: utf-8 -*-
"""CYNAPTICS TASK 1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gnJB5VoC0hC4pMm2ncMQbEmWymHk-5lE
"""

from google.colab import files
files.upload()  

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c induction-task

!unzip induction-task.zip

!ls Data

from keras.utils import to_categorical
from keras_preprocessing.image import load_img
from keras.models import Sequential
from keras.applications import MobileNetV2, ResNet152, VGG16, EfficientNetB0, InceptionV3
from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D
import os
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import numpy as np
from tqdm.notebook import tqdm
from keras.preprocessing.image import ImageDataGenerator




def createdataframe(dir):
    image_paths = []
    labels = []

 
    for item in os.listdir(dir):
        full_path = os.path.join(dir, item)

        if os.path.isdir(full_path):  
            for imagename in os.listdir(full_path):
                image_paths.append(os.path.join(full_path, imagename))
                labels.append(item)  
        else: 
            image_paths.append(full_path)
            labels.append("unknown")  

    print("Dataframe creation completed.")
    return image_paths, labels



def extract_features(images):
    features = []
    for image in tqdm(images):
        try:
            img = load_img(image, target_size=(236, 236))  
            img = np.array(img)  
            features.append(img) 
        except Exception as e:
            print(f"Error loading image {image}: {e}")  
    features = np.array(features)
    features = features.reshape(features.shape[0], 236, 236, 3)
    return features


TRAIN_DIR = "Data/Train"

train = pd.DataFrame()
train['image'], train['label'] = createdataframe(TRAIN_DIR)

train_features = extract_features(train['image'])

x_train = train_features / 255.0

le = LabelEncoder()
le.fit(train['label'])
y_train = le.transform(train['label'])
y_train = to_categorical(y_train, num_classes=2)



TEST_DIR="Data/Test"

test=pd.DataFrame()
test['image'],test['label']=createdataframe(TEST_DIR)

print("Unique labels in the test set:", test['label'].unique())
print("Labels learned by LabelEncoder:", le.classes_)

valid_labels = le.classes_
test = test[test['label'].isin(valid_labels)]



test_features = extract_features(test['image'])
x_test = test_features / 255.0

y_test = le.transform(test['label'])
y_test = to_categorical(y_test, num_classes=2)





model = Sequential()

model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(236, 236, 3)))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(1024, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(2048, activation='relu'))
model.add(Dense(2, activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(x=x_train, y=y_train, batch_size=25, epochs=20)

from tensorflow.keras.preprocessing.image import img_to_array

def prepare_test_data(test_dir, target_size=(236, 236)):

    img_files = os.listdir(test_dir)

  
    def get_img_number(filename):
 
        return int(filename.split('_')[1].split('.')[0])


    img_files.sort(key=get_img_number)

    test_images = []
    test_ids = []

    for img_name in tqdm(img_files, desc="Processing test images"):
        img_path = os.path.join(test_dir, img_name)

        try:
   
            if not os.path.exists(img_path):
                print(f"Warning: File not found: {img_path}")
                continue

            if os.path.getsize(img_path) == 0:
                print(f"Warning: Empty file: {img_path}")
                continue

            img = load_img(img_path, target_size=target_size)

            img_array = img_to_array(img)

      
            if img_array.shape != (*target_size, 3):
                print(f"Warning: Invalid image dimensions for {img_path}")
                continue


            img_array = img_array / 255.0
            test_images.append(img_array)

            clean_id = img_name.split('.')[0]
            test_ids.append(clean_id)

        except Exception as e:
            print(f"Error processing {img_path}: {str(e)}")
            continue

    if not test_images:
        raise ValueError("No valid images found in the test directory!")

    print(f"Successfully processed {len(test_images)} images")
    return np.array(test_images), test_ids


print(f"Test directory path: {TEST_DIR}")
print(f"Files in test directory: {os.listdir(TEST_DIR)[:5]} ... (showing first 5)")
print(f"Total files found: {len(os.listdir(TEST_DIR))}")


x_test, test_ids = prepare_test_data(TEST_DIR)


predictions = model.predict(x_test)
predicted_classes = np.argmax(predictions, axis=1)
predicted_labels = le.inverse_transform(predicted_classes)


submission_df = pd.DataFrame({
    'Id': test_ids,  
    'Label': predicted_labels
})


print("\nSubmission DataFrame Info:")
print(submission_df.info())
print("\nFirst 5 rows:")
print(submission_df.head())
print("\nLast 5 rows:")
print(submission_df.tail())

submission_df.to_csv('submission.csv', index=False)
print("\nSubmission file saved as 'submission.csv'")
